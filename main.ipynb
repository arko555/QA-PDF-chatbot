{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain import HuggingFaceHub\n",
    "\n",
    "#repo_id = \"google/flan-t5-xl\" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "\n",
    "#llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":0}, huggingfacehub_api_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = pn.widgets.FileInput(width=300)\n",
    "\n",
    "openaikey = pn.widgets.PasswordInput(\n",
    "    value=\"\", placeholder=\"Enter your OpenAI API Key here...\", width=300\n",
    ")\n",
    "prompt = pn.widgets.TextEditor(\n",
    "    value=\"\", placeholder=\"Enter your questions here...\", height=160, toolbar=False\n",
    ")\n",
    "run_button = pn.widgets.Button(name=\"Run!\")\n",
    "\n",
    "select_k = pn.widgets.IntSlider(\n",
    "    name=\"Number of relevant chunks\", start=1, end=5, step=1, value=2\n",
    ")\n",
    "select_chain_type = pn.widgets.RadioButtonGroup(\n",
    "    name='Chain type', \n",
    "    options=['stuff', 'map_reduce', \"refine\", \"map_rerank\"]\n",
    ")\n",
    "\n",
    "widgets = pn.Row(\n",
    "    pn.Column(prompt, run_button, margin=5),\n",
    "    pn.Card(\n",
    "        \"Chain type:\",\n",
    "        pn.Column(select_chain_type, select_k),\n",
    "        title=\"Advanced settings\", margin=10\n",
    "    ), width=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(file, query, chain_type, k):\n",
    "    # load document\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split the documents into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    # select which embeddings we want to use\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create the vectorestore to use as the index\n",
    "    db = Chroma.from_documents(texts, embeddings)\n",
    "    # expose this index in a retriever interface\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chain to answer questions \n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(), chain_type=chain_type, retriever=retriever, return_source_documents=True)\n",
    "    result = qa({\"query\": query})\n",
    "    print(result['result'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prioritize the skills you should practice by developing the skills specifically noted in the “Top 3 Skill Areas to Prioritize When Preparing to Retake the Exam” section of this report. Remember, this list may not represent all the skills you need to practice in order to pass the exam, so you should also focus on the skills measured in the content areas where you had the weakest performance, as represented by the shortest bars on the chart. Although some skills in those content areas might overlap with those identified as priorities, practicing all skills in the content areas of your weakest performance should help improve overall performance in those areas.\n"
     ]
    }
   ],
   "source": [
    "#result = qa(r\"C:\\Users\\hp\\Downloads\\scorereport.pdf\", \"how to improve performance\", \"stuff\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convos = []  # store all panel objects in a list\n",
    "\n",
    "def qa_result(_):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openaikey.value\n",
    "    \n",
    "    # save pdf file to a temp file \n",
    "    if file_input.value is not None:\n",
    "        file_input.save(\"/.cache/temp.pdf\")\n",
    "    \n",
    "        prompt_text = prompt.value\n",
    "        if prompt_text:\n",
    "            result = qa(file=\"/.cache/temp.pdf\", query=prompt_text, chain_type=select_chain_type.value, k=select_k.value)\n",
    "            convos.extend([\n",
    "                pn.Row(\n",
    "                    pn.panel(\"\\U0001F60A\", width=10),\n",
    "                    prompt_text,\n",
    "                    width=600\n",
    "                ),\n",
    "                pn.Row(\n",
    "                    pn.panel(\"\\U0001F916\", width=10),\n",
    "                    pn.Column(\n",
    "                        result[\"result\"],\n",
    "                        \"Relevant source text:\",\n",
    "                        pn.pane.Markdown('\\n--------------------------------------------------------------------\\n'.join(doc.page_content for doc in result[\"source_documents\"]))\n",
    "                    )\n",
    "                )\n",
    "            ])\n",
    "            #return convos\n",
    "    return pn.Column(*convos, margin=15, width=575, min_height=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_interactive = pn.panel(\n",
    "    pn.bind(qa_result, run_button),\n",
    "    loading_indicator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pn.WidgetBox('*Output will show up here:*', qa_interactive, width=630, scroll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout\n",
    "pn.Column(\n",
    "    pn.pane.Markdown(\"\"\"\n",
    "    ## \\U0001F60A! Question Answering with your PDF file\n",
    "    \n",
    "    1) Upload a PDF. 2) Enter OpenAI API key. This costs $. Set up billing at [OpenAI](https://platform.openai.com/account). 3) Type a question and click \"Run\".\n",
    "    \n",
    "    \"\"\"),\n",
    "    pn.Row(file_input,openaikey),\n",
    "    output,\n",
    "    widgets\n",
    "\n",
    ").servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbotpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
